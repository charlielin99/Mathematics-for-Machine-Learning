{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Mean/Covariance of a data set and effect of linear transformation\n",
    "\n",
    "In this week, we are going to investigate how the mean and (co)variance of a dataset changes\n",
    "when we apply affine transformation to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "1. Get Farmiliar with basic programming using Python and Numpy/Scipy.\n",
    "2. Learn to appreciate implementing\n",
    "   functions to compute statistics of dataset in vectorized way.\n",
    "3. Understand the effects of affine transformations on a dataset.\n",
    "4. Understand the importance of testing in programming for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few links for your reference. You may want to refer back to them throughout the whole course.\n",
    "\n",
    "- If you are less comfortable with programming in Python, have a look at this Coursera course https://www.coursera.org/learn/python.\n",
    "- To learn more about using Scipy/Numpy, have a look at the [Getting Started Guide](https://scipy.org/getting-started.html). You should also refer to the numpy [documentation](https://docs.scipy.org/doc/) for references of available functions.\n",
    "\n",
    "- If you want to learn more about creating plots in Python, checkout the tutorials found on matplotlib's website \n",
    "https://matplotlib.org/tutorials/index.html. Once you are more familiar with plotting, check out this excellent blog post http://pbpython.com/effective-matplotlib.html.\n",
    "\n",
    "- There are more advanced libraries for interactive data visualization. For example, [bqplot](https://github.com/bloomberg/bqplot) or [d3.js](https://d3js.org/). You may want to check out other libraries if you feel adventurous.\n",
    "\n",
    "- Although we use Jupyter notebook for these exercises, you may also want to check out [Jupyter Lab](https://github.com/jupyterlab/jupyterlab) when you want to work on your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the packages that we will use for the week. Run the cell below to import the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PACKAGE: DO NOT EDIT\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.datasets import fetch_lfw_people, fetch_mldata, fetch_olivetti_faces\n",
    "import time\n",
    "import timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to retrieve Olivetti faces dataset.\n",
    "\n",
    "When working with some datasets, before digging into further analysis, it is almost always\n",
    "useful to do a few things to understand your dataset. First of all, answer the following\n",
    "set of questions:\n",
    "\n",
    "1. What is the size of your dataset?\n",
    "2. What is the dimensionality of your data?\n",
    "\n",
    "The dataset we have are usually stored as 2D matrices, then it would be really important\n",
    "to know which dimension represents the dimension of the dataset, and which represents\n",
    "the data points in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_shape = (64, 64)\n",
    "# Load faces data\n",
    "dataset = fetch_olivetti_faces()\n",
    "faces = dataset.data\n",
    "\n",
    "print('Shape of the faces dataset: {}'.format(faces.shape))\n",
    "print('{} data points'.format(faces.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your dataset are images, it's a really good idea to see what they look like.\n",
    "\n",
    "One very\n",
    "convenient tool in Jupyter is the `interact` widget, which we use to visualize the images (faces). For more information on how to use interact, have a look at the documentation [here](http://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@interact(n=(0, len(faces)-1))\n",
    "def display_faces(n=0):\n",
    "    plt.figure()\n",
    "    plt.imshow(faces[n].reshape((64, 64)), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mean and Covariance of a Dataset\n",
    "\n",
    "You will now need to implement functions to which compute the mean and covariance of a dataset.\n",
    "\n",
    "There are two ways to compute the mean and covariance. The naive way would be to iterate over the dataset\n",
    "to compute them. This would be implemented as a `for` loop in Python. However, computing them for large\n",
    "dataset would be slow. Alternatively, you can use the functions provided by numpy to compute them, these are much\n",
    "faster as numpy uses machine code to compute them. You will implment function which computes mean and covariane both\n",
    "in the naive way and in the fast way. Later we will compare the performance between these two approaches. If you need to find out which numpy routine to call, have a look at the documentation https://docs.scipy.org/doc/numpy/reference/.\n",
    "It is a good exercise to refer to the official documentation whenever you are not sure about something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When you implement the functions for your assignment, make sure you read\n",
    "the docstring which dimension of your inputs corresponds to the number of data points and which \n",
    "corresponds to the dimension of the dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def mean_naive(X):\n",
    "    \"\"\"Compute the mean for a dataset by iterating over the dataset\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X: (N, D) ndarray representing the dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean: (D, ) ndarray which is the mean of the dataset.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    mean = np.zeros(D)\n",
    "    for n in range(N):\n",
    "        mean = np.zeros(D) # EDIT THIS\n",
    "    return mean\n",
    "\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def cov_naive(X):\n",
    "    \"\"\"Compute the covariance for a dataset\n",
    "    Arguments\n",
    "    ---------\n",
    "    X: (N, D) ndarray representing the dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    covariance: (D, D) ndarray which is the covariance matrix of the dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    covariance = np.zeros((D, D))\n",
    "    for n in range(N):\n",
    "        covariance = np.zeros((D, D)) # EDIT THIS\n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def mean(X):\n",
    "    \"\"\"Compute the mean for a dataset\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X: (N, D) ndarray representing the dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean: (D, ) ndarray which is the mean of the dataset.\n",
    "    \"\"\"\n",
    "    mean = np.zeros(X.shape[1]) # EDIT THIS\n",
    "    return mean\n",
    " \n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def cov(X):\n",
    "    \"\"\"Compute the covariance for a dataset\n",
    "    Arguments\n",
    "    ---------\n",
    "    X: (N, D) ndarray representing the dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    covariance_matrix: (D, D) ndarray which is the covariance matrix of the dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "    # It is possible to vectorize our code for computing the covariance, i.e. we do not need to explicitly\n",
    "    # iterate over the entire dataset as looping in Python tends to be slow\n",
    "    N, D = X.shape\n",
    "    covariance_matrix = np.zeros(D, D) # EDIT THIS\n",
    "    return covariance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `mean` function implemented, let's take a look at the _mean_ face of our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_face(faces):\n",
    "    \"\"\"Compute the mean of the `faces`\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    faces: (N, 64 * 64) ndarray representing the faces dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_face: (64, 64) ndarray which is the mean of the faces.\n",
    "    \"\"\"\n",
    "    mean_face = mean(faces)\n",
    "    return mean_face\n",
    "\n",
    "plt.imshow(mean_face(faces).reshape((64, 64)), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put things into perspective, we can benchmark the two different implementation with the `%time` function\n",
    "in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have some huge data matrix, and we want to compute its mean\n",
    "X = np.random.randn(100000, 20)\n",
    "# Benchmarking time for computing mean\n",
    "%time mean_naive(X)\n",
    "%time mean(X)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Benchmarking time for computing covariance\n",
    "%time cov_naive(X)\n",
    "%time cov(X)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also see how running time increases as we increase the size of our dataset.\n",
    "In the following cell, we run `mean`, `mean_naive` and `cov`, `cov_naive` for many times on different sizes of\n",
    "the dataset and collect their running time. If you are less familiar with Python, you may want to spend\n",
    "some time understanding what the code does. __Understanding how your code scales with the size of your dataset (or dimensionality of the dataset) is crucial__ when you want to apply your algorithm to larger dataset. This is really important when we propose alternative methods a more efficient algorithms to solve the same problem. We will use these techniques again later in this course to analyze the running time of our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time(f, repeat=100):\n",
    "    \"\"\"A helper function to time the execution of a function.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    f: a function which we want to time it.\n",
    "    repeat: the number of times we want to execute `f`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the mean and standard deviation of the execution.\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    for _ in range(repeat):\n",
    "        start = timeit.default_timer()\n",
    "        f()\n",
    "        stop = timeit.default_timer()\n",
    "        times.append(stop-start)\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fast_time = []\n",
    "slow_time = []\n",
    "\n",
    "for size in np.arange(100, 5000, step=100):\n",
    "    X = np.random.randn(size, 20)\n",
    "    f = lambda : mean(X)\n",
    "    mu, sigma = time(f)\n",
    "    fast_time.append((size, mu, sigma))\n",
    "    \n",
    "    f = lambda : mean_naive(X)\n",
    "    mu, sigma = time(f)\n",
    "    slow_time.append((size, mu, sigma))\n",
    "\n",
    "fast_time = np.array(fast_time)\n",
    "slow_time = np.array(slow_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(fast_time[:,0], fast_time[:,1], fast_time[:,2], label='fast mean', linewidth=2)\n",
    "ax.errorbar(slow_time[:,0], slow_time[:,1], slow_time[:,2], label='naive mean', linewidth=2)\n",
    "ax.set_xlabel('size of dataset')\n",
    "ax.set_ylabel('running time')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## === FILL IN THIS, follow the approach we have above ===\n",
    "fast_time_cov = []\n",
    "slow_time_cov = []\n",
    "for size in np.arange(100, 5000, step=100):\n",
    "    X = np.random.randn(size, 20)\n",
    "    f = None               # EDIT THIS\n",
    "    mu, sigma = None, None # EDIT THIS\n",
    "    fast_time_cov.append((size, mu, sigma))\n",
    "    \n",
    "    f = None         # EDIT THIS\n",
    "    mu, sigma = None # EDIT THIS\n",
    "    slow_time_cov.append((size, mu, sigma))\n",
    "\n",
    "fast_time_cov = np.array(fast_time_cov)\n",
    "slow_time_cov = np.array(slow_time_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(fast_time_cov[:,0], fast_time_cov[:,1], fast_time_cov[:,2], label='fast covariance', linewidth=2)\n",
    "ax.errorbar(slow_time_cov[:,0], slow_time_cov[:,1], slow_time_cov[:,2], label='naive covariance', linewidth=2)\n",
    "ax.set_xlabel('size of dataset')\n",
    "ax.set_ylabel('running time')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Affine Transformation of Dataset\n",
    "In this week we are also going to verify a few properties about the mean and\n",
    "covariance of affine transformation of random variables.\n",
    "\n",
    "Consider a data matrix $\\boldsymbol{X}$ of size (N, D). We would like to know\n",
    "what is the covariance when we apply an affine transformation $\\boldsymbol{A}\\boldsymbol{x}_i + \\boldsymbol{b}$ with a matrix $\\boldsymbol A$ and a vector $\\boldsymbol b$ to each datapoint $\\boldsymbol{x}_i$ in $\\boldsymbol{X}$, i.e.\n",
    "we would like to know what happens to the mean and covariance for the new dataset if we apply affine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def affine_mean(mean, A, b):\n",
    "    \"\"\"Compute the mean after affine transformation\n",
    "    Args:\n",
    "        mean: ndarray, the mean vector\n",
    "        A, b: affine transformation applied to x\n",
    "    Returns:\n",
    "        mean vector after affine transformation\n",
    "    \"\"\"\n",
    "    affine_m = np.zeros(mean.shape) # EDIT THIS\n",
    "    return affine_m\n",
    "\n",
    "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
    "def affine_covariance(S, A, b):\n",
    "    \"\"\"Compute the covariance matrix after affine transformation\n",
    "    Args:\n",
    "        S: ndarray, the covariance matrix\n",
    "        A, b: affine transformation applied to each element in X        \n",
    "    Returns:\n",
    "        covariance matrix after the transformation\n",
    "    \"\"\"\n",
    "    affine_cov = np.zeros(S.shape) # EDIT THIS\n",
    "    return affine_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the two functions above are implemented, we can verify the correctness our implementation. Assuming that we have some matrix $\\boldsymbol A$ and vector $\\boldsymbol b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random = np.random.RandomState(42)\n",
    "A = random.randn(4,4)\n",
    "b = random.randn(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can generate some random dataset $\\boldsymbol{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = random.randn(100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that for some dataset $\\boldsymbol X$, the mean and covariance are $\\boldsymbol m$, $\\boldsymbol S$, and for the new dataset after affine transformation $ \\boldsymbol X'$, the mean and covariance are $\\boldsymbol m'$ and $\\boldsymbol S'$, then we would have the following identity:\n",
    "\n",
    "$$\\boldsymbol m' = \\text{affine_mean}(\\boldsymbol m, \\boldsymbol A, \\boldsymbol b)$$\n",
    "\n",
    "$$\\boldsymbol S' = \\text{affine_covariance}(\\boldsymbol S, \\boldsymbol A, \\boldsymbol b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = ((A @ (X.T)).T + b)  # applying affine transformation once\n",
    "X2 = ((A @ (X1.T)).T + b) # and again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very useful way to compare whether arrays are equal/similar is use the helper functions\n",
    "in `numpy.testing`. the functions in `numpy.testing` will throw an `AssertionError` when the output does not satisfy the assertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(mean(X1), affine_mean(mean(X), A, b))\n",
    "np.testing.assert_almost_equal(cov(X1),  affine_covariance(cov(X), A, b))\n",
    "print('correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the `???` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(mean(X2), affine_mean(mean(???), A, b))\n",
    "np.testing.assert_almost_equal(cov(X2),  affine_covariance(cov(???), A, b))\n",
    "print('correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the numpy [documentation](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.testing.html)\n",
    "for details.\n",
    "\n",
    "If you are interested in learning more about floating point arithmetic, here is a good [paper](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6768)."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "mathematics-machine-learning-pca",
   "graded_item_id": "YoDq1",
   "launcher_item_id": "vCPZ0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
